\lab{Complex Integration}{Integration in the Complex Plane}{Integration in the Complex Plane}

\objective{Understand the basics of integration in the complex plane}

\section*{Residues}

We will now introduce another form of series representation of functions.
A Laurent series of a function is a series of the form $$\sum_{n= -\infty}^{\infty} a_n (z-z_0)^n$$
It can be proven that 
$$a_n = \frac{1}{2\pi i} \int_C \frac{f(z)}{(z-z_0)^{n+1}} dz$$ 
It can also be proven that this series representation is unique.
This sort of series can be generated whether or not $f$ has a singular point a $z_0$.
When $f$ does not have a singularity at $z_0$ this representation degenerates to a normal Taylor Series (with the derivatives evaluated by the formula for the $n$th derivative of an analytic function).
Where $C$ is a contour which passes counterclockwise around the singularity exactly once.
This is called Laurent's Theorem.
By analyzing the convergence of this series, we see that it will either converge for all points except possibly $z_0$ in the complex plane, converge on an annulus about $z_0$, or not converge at all.

The built in function \li{sympy.series} can evaluate the series expansion of a function at a singularity, for example
\begin{lstlisting}
import sympy as sy
z = sy.Symbol('z')
(1/sy.sin(z)).series(z,0,8)
\end{lstlisting}

\begin{problem}
Write a python function which takes $f$, $z_0$, the lowest power term in the Laurent Series, and the highest power term in the Laurent Series and returns a callable function for the desired series. Choose a small circle around $z_0$ as the contour on which to integrate ( remember, it doesn't matter what contour you use, as long as $z_0$ is inside it). Also have your function return an array with the coefficients so that you can compare your function against \li{sympy.series}.
\end{problem}

which evaluates the series expansion of the $\csc(z)$ at $z=0$. 
As is the case with Taylor Series, often the Laurent Series expansion of a function is not computed directly using it's integral definition.
It is, rather, obtained by substitution into known series.
For example, 
$$e^z = \sum_{n=0}^{\infty} \frac{z^n}{n!}$$ so we may say,
$$e^{1/z} = \sum_{n=0}^{\infty} \frac{1}{n! z^n}$$

\begin{problem}
Find the Laurent Series expansion of the function $\frac{e^{z}}{z^2 +1}$
\end{problem}

The term corresponding to $n=-1$ in the Laurent Series expansion of a complex function $f$ about a singularity $z_0$ is called the residue of $f$ at $z_0$ and is often written $\Res{z=z_0} f(z)$.
From Laurent's Theorem, using $f$, $z_0$, and $C$ as defined above, we have that $$\Res{z=z_0} f(z) = \frac{1}{2 \pi i} \int_C f(z) dz$$.
Another major theorem in Complex Analysis is the residue theorem (Also called Cauchy's Residue Theorem) which states that for some contour $C$ which does not intersect itself and a function $f$ analytic on $C$ and on the interior of $C$ except for isolated singular points $z_1,...,z_n$, that 
$$\int_C f(z) dz = 2 \pi i \sum_{k=1}^{n} \Res{z=z_k} f(z)$$
This allows for the evaluation of integrals that might not be pleasant in other circumstances.
%% Maybe an example would be nice here... idk. That'll mostly be in the next lab though.
Here are a few definitions that are good to know when speaking of residues.
\begin{itemize}
\item A singular point $z_0$ is said to be an ``isolated singular point" of a function $f$ if no sequence of singular points of $f$ converges to it.
\item An isolated singular point $z_0$ is said to be a removable singular point of a function $f$ if there are no negative powers of $(z-z_0)$ in the Laurent series expansion of $f$.
\item An isolated singular point $z_0$ is said to be a pole of a function $f$ is there are finitely may terms containing negative powers of $(z-z_0)$ in the Laurent series expansion of $f$. 
\item An isolated singular point $z_0$ is said to be an essential singular point of a function $f$ if there are infinitely many negative powers of $(z-z_0)$ in the Laurent series expansion of $f$.
\end{itemize}

\begin{comment}
\begin{problem}
Evaluate the residue of $\sin(\frac{1}{z})$ at $z=0$ by substituting into known Taylor series expansions.
Check your result numerically.
\end{problem}

\begin{problem}
There is a direct relationship between the partial fraction decomposition of the reciprocal of a polynomial and the residues of that function at its zeroes.
Show why this is true, and, using the Newton's method function you have already written, write a function which, given the coefficients for a polynomial, returns the coefficients for the partial fraction decomposition of its reciprocal with the zeroes corresponding to each coefficient.
\end{problem}
\end{comment}
