\lab{Application}{Facial Recognition using Eigenfaces}{Facial Recognition using Eigenfaces}
\label{lab:FacialRecognition}

\objective{In this lab we use the singular value decomposition to build a facial recognition system.}

Suppose we have a large database containing images of human faces together with identification information for each face.
Given an unidentified facial image, we would like to find a matching face in the database, thereby identifying the person in the image.
Such a task is known as \emph{facial recognition}.
This task may come up, for example, in law enforcement, when attempting to identify unknown persons in surveillance footage.
As humans, it is generally easy to compare two face images and determine whether the faces belong to the same person.
However, it becomes impractical for humans to visually compare one face image with several thousand other face images in a database.
Hence, we need a computational technique that automates the process of facial recognition.
One particularly simple and effective technique is known as \emph{eigenfaces}, which we now explore.

\section*{Eigenfaces}
The method of eigenfaces provides a mathematical and computational technique for efficiently storing and querying a database of face images.
As the name suggests, this method involves eigenvalues and eigenvectors of matrices related to the collection of face images at hand.
At its core, the method of eigenfaces maps each face image to a low-dimensional representation in a way that highlights the distinguishing
characteristics of the face while suppressing the irrelevant and unnecessary details.
In this light, eigenfaces can be viewed as a means of dimensionality reduction.
Let's get into the nuts and bolts of how this works.

Suppose we have a collection of $k$ face images represented as vectors $f_1, f_2, \ldots, f_k$ of length $l$.
(A digital image is normally represented by a $m \times n$ array of pixel values, but we can represented as a vector in $\mathbb{R}^{mn}$ by simply concatenating the rows of the array.)
Define the \emph{mean face} $\mu$ to be the average of each face vector:
\[
\mu = \frac{1}{k}\sum_{i=1}^k f_i.
\]
For each $i = 1,\ldots, k$, define $\bar{f}_i := f_i - \mu$.
These mean-shifted face vector $\bar{f}_i$ represents how the $i$-th face deviates from the average, and thus captures more directly the unique and distinguishing features of the face.
Now form the $l \times K$ matrix $A$ whose columns are given by the mean-shifted face vectors, i.e.
\[
A = \begin{bmatrix}
\bar{f}_1 & \bar{f}_2 & \cdots & \bar{f}_k
\end{bmatrix}.
\]

Thus far, we have obtained the mean face vector $\mu$ and a representation of our collection of face images via the matrix $A$.
With just this matrix and the mean vector, how might we go about searching our collection of face images for the closest match to a new face image $g$?
A straightforward approach is to subtract the mean face vector from $g$, obtaining $\bar{g} = g-\mu$, and then compute the Euclidean distance from
$\bar{g}$ to each mean-shifted face vector $\bar{f}_i$, i.e. compute the Euclidean distance between $\bar{g}$ and each column of $A$. 
Having done so, we can then choose the index $i$ where this distance $\|\bar{g}-\bar{f}_i\|_2$ is smallest, and return the $i$-th face image as the best match.
Although this approach is quite sensible, there are a few issues. 
Firstly, as the number of face images in our database grows large, both storing the full matrix $A$ and computing $\|\bar{g}-\bar{f}_i\|_2$ for all $i$
become increasingly difficult from a computational standpoint.
Secondly -- and this is the more important point -- calculating the Euclidean distance between two face images in the standard basis may not be the best measure
of how similar the two faces are (and empirical evidence supports this).
For example, if we have two images of the same face but with different backgrounds, the Euclidean distance between the face vectors may be very large, 
since in the standard basis, every pixel is weighted equally.
Given these issues, it is natural to ask ourselves whether there exists a low-dimensional subspace with a basis in which we can represent our
face images with minimal error and where the Euclidean distance is a more robust measure of face similarity.

Fortunately, we can produce just such a basis using the singular value decomposition of $A$. 
We first compute the decomposition $A = U\Sigma V^*$, and then \emph{truncate} the decomposition by discarding all but the largest $m$ singular values 
(and the corresponding columns of $U$ and $V$), obtaining the truncated matrices $\hat{U}, \hat{\Sigma}, \hat{V}$.
The columns of $\hat{U}$ are vectors in $\mathbb{R}^l$, and form an orthogonal basis in which the face vectors $f_i$ can be well-approximated.  

\section*{Preparing the data}

Through the course of this lab we will be building a class called \li{FacialRec} to handle everything in the facial recognition system.
In the \li{specs.py} file included with this lab there is an outline of this class along with some helper functions to help us test our system.

To populate our database, we will need some images of faces.
There are many databases available online, many of which would work with our project.
However, the algorithm which we will use is not completely robust, it requires the images to have similar lighting conditions and head positions.
Tilted head, dark lighting, wearing glasses, and different hairstyles can disrupt the algorithm.
Therefore, we need a database that contains images with consistent lighting and head posistions.
Also, to make the programming easier, we would like the images to be of the same file type and size.
The University of Essex has such a database at http://cswww.essex.ac.uk/mv/allfaces/index.html, (as well as other databases with varied head positions and lighting conditions) which we will use.

The function \li{getImages} included in the specifications file loads all the JPG files from a directory into a 3 dimensional array.
The first dimension specifices the image while the other two give the grayscale image in a 2D array.
We can also use the function \li{showImage} to display the 2D grayscale images.
This will be useful for testing the database.

\begin{problem}
Download the faces94 database from the University of Essex from http://cswww.essex.ac.uk/mv/allfaces/index.html.
Initialize a \li{FacialRec} object using the file path to the directory and have it use every 50$^{th}$ face in the database.
Also, for testing purposes, use the function \li{getImages} to put the whole database into an array of images.
Then use \li{showImage} to show the first image.
\end{problem}

Now that we have images, we need to calculate a few things before we can compute the eigenfaces from the covariance matrix.
We have already reduced the images to grayscale images in \li{getImages} to make computations easier.
Now we need the mean face of all the faces in the database. The mean face is a 2D array of each pixel average across the database.
Next we need to zero out the images using the mean face.
We will substract the mean face from each face in the database, giving the the difference faces.
Then we flatten the each 2D image into a one dimensional vector so that we have each image described in single vector space.

\begin{problem}
Implement the functions \li{initMeanImage} and \li{initDifferences}.
\li{initMeanImage} should store in \li{self.meanImage} the image of the means across each pixel in the entire database.
\li{initDifferences} should first initilize \li{self.differenceFaces} to be an array of each image in the database minus the mean image.
\li{self.differenceVectors} should be the matrix with the flattened vector of each image in the database as its rows.
If the database has 75 images each of size $200 \times 180$, then \li{self.differenceVectors} should be $75 \times 36000$.
Also, plot the mean face and the first difference face.
\end{problem}

\begin{figure}
\includegraphics[width=0.3\textwidth]{meanFace.png}
\caption{Mean face of University of Essex male data}
\label{facialRecognition:meanFace}
\end{figure}

\begin{figure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{differenceFace0.png}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{differenceFace1.png}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{differenceFace2.png}
\end{subfigure}
\caption{First three difference faces of University of Essex male data}
\label{facialRecognition:differenceFaces}
\end{figure}

\section*{Computing the Eigenfaces with SVD}

With these pelimanaries ready, we are now able to construct the Eigenfaces of the system from the covariance matrix.
At this point we have each image descibed in a vector space with as many pixels as there are in each image.
With the database we are using, this is a 36000 dimensional vector space.
There are too many random variables to work with at this point to work with, so we need to find some way to simplify the vector space.

We do this using the eigenvectors of the covariance matrix (which we call the eigenfaces).
The eigenfaces form a basis of all possible faces, so all faces could be expressed as a linear combination of eigenfaces from the covariance matrix gathered from faces in the database.
The corresponding eigenvalues of the eigenfaces give the weight or importance of each eigenface.
Now there the covariance matrix is still very large 36000 and could have many distinct eigenvectors.
However, only eigenfaces corresponding to higher eigenvalues really make a difference.
Infact, it turns out that there are only as many eigenvalues as there are images in the database.

Recall that taking the SVD of a real valued matrix $A$ gives us the eigenvectors of the matrix $AA^T$ in the columns of $V$.
If the difference vectors are denoted by $E$, then the covariance matrix is $C = EE^T$.
It then follows that we can use the SVD of $E$ to compute the eigenvectors of $C = EE^T$.

The \li{svd} function from \li{scipy.linalg} returns $U,V,V^T$. You can then get the eigenfaces with a call like
\begin{lstlisting}
u,s,vT = la.svd(self.differenceVectors,full_matricies=False)
self.eigenfaces = vT
\end{lstlisting}
This will put into \li{eigenfaces} the eigenfaces of the database as its rows.

\begin{problem}
Implement the function \li{initEigenfaces} by computing the eigenfaces of the images in the database using the SVD and storing them in \li{self.eigenfaces}.
The eigenfaces should be in the columns of \li{self.eigenfaces} so that it becomes a $36000 \times 75$ matrix.
Plot the first three eigenfaces.
\end{problem}

\begin{figure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{eigenface0.png}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{eigenface1.png}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{eigenface2.png}
\end{subfigure}
\caption{First three eigenfaces of University of Essex male data}
\label{facialRecognition:eigenfaces}
\end{figure}

With the eigenfaces computed, we can now convert vectors representing faces into the eigenface space and back.
To convert to the eigenface space we first subtract off the mean face, flatten the vector, then project the vector on the eigenfaces.
To rebuild an image from its representation in eigenfaces, we simply add up the linear combination of eigenfaces then add back in the mean.

\begin{problem}
Implement the functions \li{projectToImageFaceSpace} and \li{rebuildFromEigenfaces}.
\li{projectToImageFaceSpace} should project an image into its coordinates in the basis of the eigenfaces.
\li{rebuildFromEigenfaces} should undo that projection by taking the coordinates in the eigenface space, projecting them back, and reshaping the image.
\end{problem}

\begin{figure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{rebuiltAll.png}
\caption{All the eigenfaces}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{rebuiltHalf.png}
\caption{Half of the eigenfaces}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{rebuiltFourth.png}
\caption{Fourth of the eigenfaces}
\end{subfigure}
\caption{Image rebuilt with varying number of eigenfaces}
\label{facialRecognition:rebuiltImage}
\end{figure}

\section*{Creating the Facial Recognition System}

The facial recognition database is almost done.
Given a face to seach for, we only have to project it into the eigenface basis and then perform a nearest neighbor seach for the closest image.

\begin{problem}
Implement the functions \li{initClassifier}, and \li{findNearest}.
\li{initClassifier} should initialize \li{self.nbrs} as a \li{sklearn.neighbors.KNearestNeighbors} with \li{nearest_neighbors=1}.
Create a set of training points from the images in the database projected into the eigenface basis and use the first \li{searchOrder} number of coefficeints in the \li{self.nbrs.fit} function.
For the labels give the indicies of the labels in the database (this can be done with \li{range})

Implement \li{findNearest} by subtracting off the mean face from the image and then projecting it into the eigenface basis.
Then perform a nearest neighbor search with the coefficeints up to \li{searchOrder} using \li{self.nbrs.predict}.
This will return an index to the matching image.

We also want to compute the distance of the image to the matching image to see if it's really a good match.
Do this by projecting the matching image to the eigenface basis and then taking the norm of its difference from the image passed in but in the eigenface basis.
\end{problem}

\begin{problem}
Verification

Your facial recognition database should be working now.
Try it on some exact images that are in the database, some faces that are in the database but that aren't exact copies, and faces that aren't in the database at all.
(Pick a random image from the full set, it probably won't be in the database.
 All images that are a multiple of \li{fileStep} are in the database.
 Indicies close to these are probably of the same person but a different picture.
 As you do all of these take note of the distance between the match and the image.
 Chose a reasonable limiting distance to designate a match or false match and add whether this condition is satisfied as a boolean.
\end{problem} 