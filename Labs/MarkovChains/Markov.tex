\lab{Markov Chains}{Markov Chains}
\label{lab:Markov}

\objective{}

\section*{Introduction}
Markov chains are relatively straightforward mathematical objects with far ranging applications.

\section*{Definition and Implementation}

Suppose that we wish to model a system that can be in a finite number of states.
A Markov chain is a collection of states with the probabilities that we will move from one state to another.
An example of a Markov chain is a board game where players move around the board based on die rolls.
In this case, the probability of moving from one space to another only depends on the players current location.
Where the player was on a previous turn does not affect their current turn.

Markov chains have an associated transition matrix that stores all the information about the chain.
The $(ij)^{th}$ entry of the matrix gives the probability of moving from state $j$ to state $i$.
The columns of the transition matrix must sum to 1.

Consider a very simple weather model, where the probability of being hot or cold depends on the weather of the previous day.
If the probability that tomorrow is hot given that today is hot is 0.7, and the probability that tomorrow is cold given that today is cold is 0.4, then this Markov chain has the following transition matrix:
\[ \left( \begin{array}{cc}
0.7 & 0.6 \\
0.3 & 0.4 \end{array} \right)\] 

\begin{problem}
Transition matrices for Markov chains are efficiently stored as \li{numpy} arrays.
Write a function that accepts a dimension $n$ and returns the transition matrix for a random markov chain with $n$ states.
\end{problem}

\section*{Markov Chains as Data Generators}

One application of Markov chains is modelling natural processes.
For example, consider our simple weather model from the previous section.
If we choose a start state, we can produce a sequence of predictions of arbitrary length.

\subsection*{Simulating a state transition}
We may simulate moving from state to state by sampling from a uniform distribution.
In a general Markov chain, if we are in state $j$ then the $j^{th}$ column of the transition matrix gives the probabilities of moving to any other state $i$.
By definition, these probabilities sum to $1$.
Thus, the partition the interval from $0$ to $1$, and we can choose the next state to move to by generating a random number between $0$ and $1$.
For example, suppose that we know today is hot, and we want to simulate the weather tomorrow.
The column that corresponds to ``hot'' in the transition matrix is $(0.7, 0.3)^T$.
If we generate a random number and it is less than $0.7$, then our simulation says that tomorrow will be hot.
If the random number is larger than $0.7$, then the simulation says that tomorrow will be cold.
In python, the programming logic would look like this:

\begin{lstlisting}
import numpy as np

def forecast():
	"""Forecast tomorrow's weather given that today is hot."""

	transition_matrix = np.array([[0.7, 0.6], [0.3, 0.4]])
	random_number = np.random.random()
	if random_number < transition_matrix[0,0]:
		print "Hot"
	if random_number > transition_matrix[0,0]:
		print "Cold"
\end{lstlisting}

\begin{problem}
Modify the \li{forecast} function from the previous section so that it accepts a parameter \li{num\_days} and returns a simulation of the weather for the number of days given.
\end{problem}

\begin{problem}
Suppose that we want to model weather with three states: hot, mild, and cold.
Let the transition matrix for this new Markov chain be:

\[
MATRIX GOES HERE
\]

Create a new function called \li{three_state_forecast} that accepts a parameter $num_days$ and returns a simulation of the weather.
Assume that the starting day is hot.
\end{problem}

\section*{Using Markov Chains to Simulate English}

One of the original applications of Markov chains was to study language (citation needed, but it totally was).
In the early $20^{th}$ century, Markov used his chains to model how russian switched from vowels to consonants.
By midcentury, they had been used to try and model English.

\subsection*{Modelling English}
Markov chains are insufficient to model very good English.
However, they can approach a model of bad English, with sometimes amusing results.

A Markov chain model of English has each word as a state.
By nature, a Markov chain is only concerned with its current state.
Thus, a Markov chain is unaware of context or even previous words in a sentence.
For example, a Markov chain's current state may be the word ``continuous.''
Then the chain would say that the next word in the sentence is more likey to be ``function'' rather than ``racoon.''
However, without the context of the rest of the sentence, two likely words like ``function'' and `` ''

\subsection*{Starting and Stopping states}

In the previous weather model we chose a fixed number of states to simulate.
However, in English, sentences are of varying length.
One way to simulate this is to create a start state and an end state.
To generate a new sentence, we begin in the given start state.
Subsequent words will have a probability of moving to the end state.
Once the chain moves to the end state, we have reached the end of the sentence and place a period.
This is modelled in Python with a \li{while} loop and putting the start and stop state as the first and last column of the transition matrix, respectively.

\begin{lstlisting}

# Let trans_matrix be the transition matrix of a Markov chain with a start and stop state.

current_state = 0
stop_state = trans_matrix.shape[0] # Note all transition matrices are square.

while current_state != stop_state:
	'''
	# THIS NEEDS TO BE EXPLAINED IN THE SIMULATING TRANSITIONS SECTION.
	# It's explanation is beyond their ken (as in, they don't know what a multinomial distribution
	# is.  However, it is the best way I can think of to produce the transitions.
	# Maybe put it in a function and give it to them as a black box to be understood later.
	'''
	state_vec = np.random.multinomial(1, trans_matrix[:,current_state])
	next_state = np.where(state_vec)[0][0]
	
	# Here you could do something with the next state, like add it to a list to keep track of the state
	# that the chain travels through.
	current_state = next_state
\end{lstlisting}

\begin{problem}

\end{problem}

\subsection*{Teaching the Markov Chain}

Now that we know how to travel through a Markov chain, we will build one to simulate English.
In order to do this, we need to determine the transition probabilities between words.
One way to do this would be to assign every word in English a number.  Say there are $N$ of them, and create an $N\times N$ matrix of zeros.
Then, read every written work in English and when word $j$ follows work $i$, we add 1 to the $(i,j)^{th}$ entry of the matrix.
Once we have done this for every word of every written work, we normalize the columns and have a transition matrix that we may simulate from.

The main problem with this approach is the sheer enormity of the task at hand.
We will restrict ourselves to a subproblem of modelling the English of a specific group of people.
Specifically, we will use the posts from the math stack exchange website.
(See: \li{stack_exchange_posts.txt}.
Thus, the transition probabilities of our Markov chains will reflect the sort of English that the source authors speak.
For example, the transition matrix built from the Complete Works of William Shakespeare will differ greatly from, say, a collection of academic journals.
We will call the source collection of works in the next problems the \emph{training set}.

\begin{problem}
First we will write a function that converts English to numbers.
These numbers will correspond to rows and columns in our transition matrix.
Thus, we may refer to a words column or row in the transition matrix by its number.

The function should accept the path to a file that contains the training set.
Then it should break each line into words.
Finally, for each word it should check to see if the word has been assigned a number yet.
If it hasn't, then assign the word a number and write the number into a new file.
If a number has been assigned already, write it to the new file.
The line break structure should be maintained.

For example, a text and it's conversion to numbers follows.

Love is patient love is kind
It does not envy it does not boast
It is not proud It is not rude
It is not self-seeking It is not easily angered
It keeps no record of wrongs
Love does not delight in evil
But rejoices with the truth
It always protects always trusts
Always hopes always perseveres
Love never fails

1 2 3 1 2 4 
5 6 7 8 5 6 7 9 
5 2 7 10 5 2 7 11 
5 2 7 5 2 7 12 13 
5 14 15 16 17 18 
1 6 7 19 20 21 
22 23 24 25 26 
5 27 28 27 29 
27 30 27 31 
1 32 33

Note that, for example, the word ``love'' is assigned the number 1, and the word ``it'' is assigned the number 5.
(Hint: This needs a hit about file reading and writing)

Besides writing the new file, return a list that matches the index of the list to the word assigned that number.
\end{problem}

Now that we have converted our English text into numbers, it is time to build the transition matrix for the Markov chain.
We will scan the file we created in the previous problem and use it to create the matrix.

\begin{problem}
Write a function that accepts the path to the file created in the previous problem and the number of unique words in the text (this will be the length of the list returned previously).
The function should then initialize a \emph{sparse} square zero matrix of floats (Hint: use \li{lil_matrix} from the \li{scipy.sparse} library) whose dimension is the number of unique words in the text, plus 2 (to include a start and stop state).
Then, read each line of the file and for each pair of subsequent numbers add one to the corresponding entry of the matrix.
For instance, if we use the example text of the previous problem and we scanned the line

1 6 7 19 20 21

Then we would add one to the $(1,6), (6,7), (7,19), (19,20),$ and $(20,21)^{st}$ entries of the matrix.
Also, each line should begin with the start state (assign it the number 0) and stop state (length of word list + 1), so that $(0,1)$ and $(21,34)$ would also be incremented.

Once the entire file has been read, divide each column by it's column sum.
Now each column will sum to one and it's non zero entries correspond to the probability of moving from word $i$ to word $j$.

For troubleshooting, use \li{stack_exchange_posts_small} to save time.
\end{problem}

\begin{problem}
Now that we have a Markov chain and a word list, we may simulate English sentences by travelling through the chain.
Put the example code in the \emph{Start and Stop States} section into a function and modify it so it prints a sentence generated by the chain.
This function will accept the transition matrix and word list as arguments.
Also include a keyword argument that allows you to specify the number of sentences created.

Once this is working, you may try experiments with other data sets.
We have also made the works of Shakespeare available in \li{shakespeare.txt}.
\end{problem}

